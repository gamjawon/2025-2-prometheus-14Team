# LLMì´ í•©ì„± ë‹¨ê³„ ì¶”ë¡  ì§€ì‹œ 

import json
import os
import sys
from typing import Any, Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def load_json(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def to_inorganic_material(extracted: Dict[str, Any], idx: int) -> Dict[str, Any]:
    target = extracted.get("target", {}) or {}
    reaction_string = extracted.get("reaction_string")
    mat = {
        "id": f"inorg_{idx}",
        "class": "InorganicMaterial",
        "hasName": target.get("material_string") or target.get("material_formula"),
        "hasAcronym": target.get("is_acronym"),
        "hasPhase": target.get("phase") or "",
        "isOxygenDeficiency": target.get("oxygen_deficiency"),
        "hasReaction": reaction_string
    }
    return mat


def to_precursors(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    abstract Precursor entry template only: class + key(ê°’ ì—†ìŒ)
    ê°’ì€ LLMì´ step ì „ì²´ usesPrecursorì—ì„œ uniqueí•˜ê²Œ ì¶”ë¡ í•´ ì±„ì›€
    """
    # ë¹ˆ ê°’(í˜¹ì€ None), key êµ¬ì¡°ë§Œ draftë¡œ í¬í•¨
    return [
        {
            "class": "Precursor",
            "hasName": None
        }
    ]


def to_solvents(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    sols = []
    for i, s in enumerate(extracted.get("solvents_string", []), start=1):
        sols.append({
            "id": f"solvent_{i}",
            "class": "Solvent",
            "hasName": s
        })
    return sols


def to_media(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    medias = []
    seen = set()

    for op in extracted.get("operations", []):
        cond = op.get("conditions") or {}
        mm = cond.get("mixing_media")
        if not mm:
            continue
        # mixing_mediaê°€ ë¦¬ìŠ¤íŠ¸ë¼ê³  ê°€ì • (["water"], ["ethanol", "water"] ë“±)
        for name in mm:
            if name not in seen:
                seen.add(name)
                medias.append({
                    "id": f"media_{len(medias) + 1}",
                    "class": "Media",
                    "hasName": name
                })

    return medias


#def to_abrasives(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    abrasives = []
    for i, a in enumerate(extracted.get("abrasives", []), start=1):
        abrasives.append({
            "id": f"abrasive_{i}",
            "class": "Abrasive",
            "hasName": a
        })
    return abrasives

def to_additives(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    adds = []
    for i, a in enumerate(extracted.get("additives", []), start=1):
        adds.append({
            "id": f"additive_{i}",
            "class": "Additive",
            "hasName": a.get("material_string") or a.get("material_formula") or a
        })
    return adds


def condition_from_operation(op: Dict[str, Any], idx: int) -> Optional[Dict[str, Any]]:
    conds = op.get("conditions") or {}
    if not conds:
        return None

    def extract_with_unit(block):
        """blockì—ì„œ values[0]ê³¼ unitsë¥¼ ê²°í•©í•´ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
        if not isinstance(block, dict):
            return None
        value = None
        unit = block.get("units")
        v = block.get("values")
        if isinstance(v, list) and v:
            value = v[0]
        elif "value" in block:
            value = block["value"]
        if value is None:
            return None
        if unit:
            return f"{value} {unit}"
        return str(value)

    temp = extract_with_unit(conds.get("temperature"))
    time_ = extract_with_unit(conds.get("time"))
    ph = conds.get("pH")
    pressure = extract_with_unit(conds.get("pressure"))

    if all(v is None for v in [temp, time_, ph, pressure]):
        return None

    return {
        "id": f"cond_{idx}",
        "class": "Condition",
        "hasTemperature": temp,
        "hasTime": time_,
        "haspH": str(ph) if ph is not None else None,
        "hasPressure": pressure
    }


def to_synthesis_steps(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    JSON ë°ì´í„°ì…‹ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•´ì„œ
    SynthesisStep ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“ ë‹¤.

    - operations[*] â†’ step ì‹œí€€ìŠ¤ (id, hasAction)
    - condition_from_operation â†’ performedUnder (Condition id)
    - nextStep ì²´ì¸

    ì–´ë–¤ stepì´ ì–´ë–¤ Precursor/Solvent/Media/Additive/Productë¥¼
    ì‚¬ìš©í•˜ëŠ”ì§€ëŠ” ì—¬ê¸°ì„œ ì „í˜€ ë„£ì§€ ì•ŠëŠ”ë‹¤.
    ê·¸ ë¶€ë¶„ì€ LLMì´ ontologyì™€ extractedë¥¼ ë³´ê³  ì¶”ë¡ í•˜ë„ë¡ ë§¡ê¸´ë‹¤.
    """
    steps: List[Dict[str, Any]] = []
    ops = extracted.get("operations", []) or []

    for i, op in enumerate(ops, start=1):
        step_id = f"step_{i}"
        cond = condition_from_operation(op, i)

        step: Dict[str, Any] = {
            "id": step_id,
            "class": "SynthesisStep",
            "hasAction": op.get("string") or op.get("type"),
            "hasNote": None
        }

        # JSONì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒì€ "ì´ stepì´ ì–´ë–¤ ì¡°ê±´ì—ì„œ ìˆ˜í–‰ë˜ëŠ”ê°€" ë¿
        if cond:
            step["performedUnder"] = cond["id"]

        steps.append(step)

    # step ìˆœì„œ ì •ë³´ëŠ” JSONì˜ operations ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    for i in range(len(steps) - 1):
        steps[i]["nextStep"] = steps[i + 1]["id"]

    return steps



def to_product(extracted: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    abstract Product entry template only: class + key(ê°’ ì—†ìŒ)
    ê°’ì€ LLMì´ step ì „ì²´ producesProductì—ì„œ uniqueí•˜ê²Œ ì¶”ë¡ í•´ ì±„ì›€
    """
    return [
        {
            "class": "Product",
            "hasName": None
        }
    ]

def to_synthesis_method(extracted: Dict[str, Any], first_step_id: Optional[str]) -> Dict[str, Any]:
    """
    extracted["operations"]ì˜ ê°œìˆ˜ë§Œí¼ step idë¥¼ ë§Œë“¤ì–´ì„œ, 
    'consistOfStep' í•„ë“œì— ìˆœì„œëŒ€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ì±„ìš°ê¸°.
    """
    method = {
        "id": "method_1",
        "class": "SynthesisMethod",
        "hasID": 1
    }
    
    # operationsì—ì„œ step id ë¦¬ìŠ¤íŠ¸ ìƒì„±
    ops = extracted.get("operations", []) or []
    step_ids = [f"step_{i+1}" for i in range(len(ops))]
    
    if step_ids:
        # í•œ ê°œ ì´ìƒ stepì´ ìˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ì…ë ¥
        # (stepì´ 1ê°œì´ë©´ ë‹¨ì¼ stringìœ¼ë¡œë„ í•  ìˆ˜ ìˆì§€ë§Œ, ì¼ê´€ì„±ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ)
        method["consistOfStep"] = step_ids
    
    return method


def fit_extracted_to_ontology(extracted: Dict[str, Any],
                              ontology: Dict[str, Any],
                              idx: int) -> Dict[str, Any]:
    inorg = to_inorganic_material(extracted, idx)
    precs = to_precursors(extracted)
    sols = to_solvents(extracted)
    meds = to_media(extracted)
    # abrasives = to_abrasives(extracted)  # í•„ìš”í•˜ë©´ ë‹¤ì‹œ ì‚¬ìš©
    prod = to_product(extracted)
    adds = to_additives(extracted)

    # ğŸ”¥ stepì—ëŠ” êµ¬ì¡°/ì¡°ê±´ë§Œ ë„£ê³ , ì–´ë–¤ ë¬¼ì§ˆì„ ì“°ëŠ”ì§€ëŠ” LLMì—ê²Œ ë§¡ê¹€
    steps = to_synthesis_steps(extracted)

    method = to_synthesis_method(extracted, steps[0]["id"] if steps else None)

    conditions = []
    ops = extracted.get("operations", []) or []
    for i, op in enumerate(ops, start=1):
        c = condition_from_operation(op, i)
        if c:
            conditions.append(c)

    result = {
        "InorganicMaterial": [inorg],
        "Precursor": precs,
        "Solvent": sols,
        "Media": meds,
        # "Abrasive": abrasives,
        "Product": [prod],
        "Additive": adds,
        "SynthesisMethod": [method],
        "SynthesisStep": steps,
        "Condition": conditions
    }
    return result


def llm_refine_with_ontology(
    extracted: Dict[str, Any],
    ontology: Dict[str, Any],
    draft: Dict[str, Any]
) -> Dict[str, Any]:
    """
    LLMì—ê²Œ ontologyì™€ draft(result)ë¥¼ ê°™ì´ ì£¼ê³ 
    'ontologyì— ì •ì˜ëœ í´ë˜ìŠ¤/í”„ë¡œí¼í‹°ë§Œ ì‚¬ìš©í•´ì„œ ë‹¤ì‹œ ë§Œë“¤ì–´ì¤˜'ë¼ê³  ì‹œí‚¨ë‹¤.
    draftëŠ” ë„¤ rule-based ê²°ê³¼ë¼ì„œ LLMì´ 'ì•„ ì´ëŸ° ì‹ìœ¼ë¡œ ë§¤í•‘í•˜ë ¤ê³  í–ˆêµ¬ë‚˜' í•˜ê³  ë³´ì™„í•  ìˆ˜ ìˆìŒ.
    """
    #ì…ë ¥ ë°ì´í„°ë¡œ í•´ì•¼í•  ì¼ ì •ì˜ 
    user_payload = {
        "instruction": (
    "ë‹¤ìŒ ì„¸ ê°€ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì˜¨í†¨ë¡œì§€ì— ì™„ì „íˆ ë¶€í•©í•˜ëŠ” í•©ì„± ë°ì´í„° JSONì„ ë§Œë“¤ì–´ë¼. "
    "1) ontology: ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤, ì˜¤ë¸Œì íŠ¸ í”„ë¡œí¼í‹°, ë°ì´í„° í”„ë¡œí¼í‹° ì •ì˜ "
    "2) extracted: ë…¼ë¬¸ì—ì„œ ì¶”ì¶œëœ ì›ë³¸ JSON "
    "3) draft: ì‚¬ìš©ìê°€ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ 1ì°¨ ë³€í™˜í•œ ê²°ê³¼(ì—¬ê¸°ì— step ì‹œí€€ìŠ¤ì™€ ì¡°ê±´, ë¬¼ì§ˆ ë¦¬ìŠ¤íŠ¸ê°€ ìˆì§€ë§Œ, ê° stepì— ì–´ë–¤ ë¬¼ì§ˆì´ ì—°ê²°ë˜ëŠ”ì§€ëŠ” ë¹„ì›Œì ¸ ìˆë‹¤.) "

    "ë„ˆì˜ ì£¼ìš” ì—­í• ì€ ê° SynthesisStepì— ì–´ë–¤ Precursor, Solvent, Media, Additive, Productê°€ ì—°ê²°ë˜ëŠ”ì§€ ì¶”ë¡ í•˜ì—¬ "
    "usesPrecursor, usesSolvent, usesMedia, usesAdditive, producesProduct, performedUnder, nextStep, consistOfStep ë“± í”„ë¡œí¼í‹°ë¥¼ ì±„ìš°ëŠ” ê²ƒì´ë‹¤. "
    "extracted.operationsì˜ ìˆœì„œë¥¼ ë”°ë¼ step ì‹œí€€ìŠ¤ë¥¼ êµ¬ì„±í•˜ë¼. "

    "í•˜ë‚˜ì˜ data ì•ˆì˜ ëª¨ë“  ë¬¼ì§ˆ(entity)ì€ ë°˜ë“œì‹œ SynthesisStep ë‚´ì—ì„œ ìµœì†Œí•œ í•œ ë²ˆì€ usesPrecursor, usesSolvent, usesMedia, usesAdditive, producesProduct ë“±ìœ¼ë¡œ stepì— ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤. "
    "ì–´ë–¤ ë¬¼ì§ˆë„ step ì—°ê²°ì—ì„œ ëˆ„ë½ë˜ë©´ ì•ˆ ëœë‹¤. "

    "ì¶”ë¡  ì‹œ, extractedì˜ paragraph_string, operations, reaction, quantities ë“±ì— ê·¼ê±°ê°€ ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì„ì˜ë¡œ ë§Œë“¤ì§€ ë§ê³ , "
    "í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ í”„ë¡œí¼í‹°ëŠ” ì•„ì˜ˆ ë„£ì§€ ì•Šê±°ë‚˜ null/ë¹ˆ ë°°ì—´ë¡œ ë‘ì–´ë¼. "
    "ë°˜ë“œì‹œ ontologyì— ì •ì˜ëœ ì´ë¦„(í”„ë¡œí¼í‹°, í´ë˜ìŠ¤ ë“±)ë§Œ ì¨ë¼. "

    "íŠ¹íˆ SynthesisStep ë‚´ë¶€ì—ì„œ usesPrecursor, producesProduct ë“±ì€ chemical idë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ê³ , ë°˜ë“œì‹œ ì‹¤ì œ ë¬¼ì§ˆëª…(ì˜ˆ: \"La(NO3)3Â·6H2O\", \"BaTiO3\" ë“±)ì„ ê°’ìœ¼ë¡œ ì¨ë¼. "
    "ì—¬ëŸ¬ ê°œ ë¬¼ì§ˆì´ í•œ ë‹¨ê³„ì— ì“°ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œê¸°í•˜ë¼ (ì˜ˆ: [\"TiCl4\", \"La(NO3)3Â·6H2O\"]). "
    "ê°’ì´ ì—†ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ keyëŠ” nullì´ë‚˜ ë¹ˆ ë°°ì—´ë¡œ ë‘ì–´ë„ ëœë‹¤. "
    "ê° stepì˜ input/output ì—°ê²°ê´€ê³„ ì •í™•ì„±ì— ì§‘ì¤‘í•˜ë¼. "

    "ê° stepì˜ usesPrecursor, producesProduct ë“±ì—ì„œ ë“±ì¥í•œ ëª¨ë“  unique ë¬¼ì§ˆëª…ì„ ì¤‘ë³µ ì—†ì´ ê° Precursor/Product í•„ë“œì— í•˜ë‚˜ì”©ë§Œ í¬í•¨ì‹œì¼œì•¼ í•œë‹¤. "
    "draftì—ì„œëŠ” hasNameì´ Noneì´ì§€ë§Œ, ìµœì¢… outputì€ ë°˜ë“œì‹œ í•´ë‹¹ ê°’ìœ¼ë¡œ ì±„ì›Œì•¼ í•œë‹¤. ì˜ˆì‹œ:\n"
    "\"Precursor\": [\n  { \"class\": \"Precursor\", \"hasName\": \"Al(NO3)3Â·9H2O\" }, ... ],\n"
    "\"Product\": [\n  { \"class\": \"Product\", \"hasName\": \"Pt-In/Mg(Pt)(In)(Al)Ox\" }, ... ]\n"
    "ê°’ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ë‘ì–´ë„ ëœë‹¤. "

    "SynthesisStep ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ ì˜ˆì‹œ íŒ¨í„´ì²˜ëŸ¼, id, class, hasAction, hasNote, nextStep ë“± ì£¼ìš” í‚¤ êµ¬ì¡°ë¥¼ í•­ìƒ í¬í•¨í•˜ê³ , usesPrecursor/producesProduct/usesSolvent/usesMedia ê°™ì€ ì—°ê²° ì •ë³´ëŠ” ìƒí™©ì— ë§ê²Œ ê°’ì„ ì±„ìš°ë˜, í•´ë‹¹ ê°’ì´ ì—†ìœ¼ë©´ nullì´ë‚˜ ë¹ˆ ë°°ì—´ë¡œ í‘œê¸°í•˜ë¼. "
    "ì˜ˆì‹œ 1:\n"
    "{\n"
    "  \"id\": \"step_1\",\n"
    "  \"class\": \"SynthesisStep\",\n"
    "  \"hasAction\": \"adding\",\n"
    "  \"hasNote\": null,\n"
    "  \"nextStep\": \"step_2\",\n"
    "  \"usesPrecursor\": \"La(NO3)3Â·6H2O\",\n"
    "  \"usesSolvent\": \"water\",\n"
    "  \"usesMedia\": null\n"
    "}\n"
    "ì˜ˆì‹œ 2:\n"
    "{\n"
    "  \"id\": \"step_5\",\n"
    "  \"class\": \"SynthesisStep\",\n"
    "  \"hasAction\": \"washed\",\n"
    "  \"hasNote\": null,\n"
    "  \"nextStep\": \"step_6\",\n"
    "  \"usesSolvent\": \"ethanol\"\n"
    "  \"producesProduct\": \"BaTiO3\"\n"
    "}\n"
    "ì´ êµ¬ì¡°ì™€ key íŒ¨í„´(ìˆœì„œ í¬í•¨)ì„ ëª¨ë“  stepì— ì¼ê´€ë˜ê²Œ ì ìš©í•˜ì—¬ SynthesisStep ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ë¼. "
    "draftëŠ” ë‚´ê°€ ì›í•˜ëŠ” ì¶œë ¥ ì˜¨í†¨ë¡œì§€ í‘œì¤€ ìŠ¤í‚¤ë§ˆì´ë‹ˆ, SynthesisStep ì´ì™¸ì˜ ëª¨ë“  í•„ë“œëŠ” ê°’ê³¼ êµ¬ì¡°ë¥¼ ë‹¨ í•˜ë‚˜ë„ ìˆ˜ì •í•˜ì§€ ë§ê³  draft ê·¸ëŒ€ë¡œ ì¶œë ¥í•  ê²ƒ."
    "íŠ¹íˆ, quantities field ì•ˆì˜ materialë„ precursor, mediaë“±ì´ ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì ì ˆíˆ ë¶„ë¥˜í•˜ì—¬ stepì— ë°˜ì˜í•´ë¼."
    "ì‹¤í—˜ ë§¥ë½ìƒ ì–´ë–¤ ì—­í• ë¡œ ì“°ì˜€ëŠ”ì§€ ì¶”ë¡ (ì˜ˆ: ë³´ì¡°ì œ, ì²¨ê°€ì œ, ë§¤ì§ˆ ë“±)í•´ ì˜³ì€ class/stepì— ë„£ê³ , "
    "ëª¨ë“  ë¬¼ì§ˆì„ ì ˆëŒ€ ëˆ„ë½í•˜ì§€ ë§ ê²ƒ."
    "quantities field ì•ˆì— materialì´ ìˆëŠ”ì§€ ê¼­ í™•ì¸í•  ê²ƒ"
    "ëª¨ë“  ë¬¼ì§ˆì˜ í´ë˜ìŠ¤ í• ë‹¹, step ì—°ê²°ì •ë³´ ê²°ì • ë“±ì€ ë°˜ë“œì‹œ step-by-step, ì›ì¸ê³¼ ë§¥ë½ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ê³ ë ¤í•˜ëŠ” 'chain of thought' (COT) ë°©ì‹ì˜ reasoningì„ ë‚´ë¶€ì ìœ¼ë¡œ ê±°ì³ë¼. "
    "ì‹¤ì œë¡œ reasoning ê³¼ì •ì„ ì¶œë ¥í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ëª¨ë“  ê²°ì •(ë¶„ë¥˜, ì—°ê²°, ê°’ ì±„ì›€)ì€ ìœ„ ë…¼ë¦¬ì  COT ê³¼ì •ì„ í•œ ë²ˆì”© ê±°ì¹œ ë’¤ ê²°ê³¼ë¥¼ ë‚´ë†“ì„ ê²ƒ."
    )

    


,

        "ontology": ontology,
        "extracted": extracted,
        "draft": draft
    }

    messages = [
        {   #ì—­í•  ë¶€ì—¬ (ê¼­ ì§€ì¼œì•¼í•˜ëŠ” )
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì •ì˜ ì˜¨í†¨ë¡œì§€ì— ë§ì¶° JSONì„ ì¬êµ¬ì„±í•˜ëŠ” ë³´ì¡°ìì´ë©° ì´ ì„¸ìƒ ìµœê³ ì˜ í™”í•™ìì…ë‹ˆë‹¤. "
                "ì˜¨í†¨ë¡œì§€ì— ì—†ëŠ” í´ë˜ìŠ¤ë‚˜ í”„ë¡œí¼í‹°ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”. "
                "domainê³¼ range ì •ë³´ê°€ ìˆì„ ê²½ìš° ì´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ë”°ë¥´ì„¸ìš”. "
                "ë°˜ë“œì‹œ JSON ê°ì²´ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
                "ontology.jsonì˜ description í•„ë“œì— ì„¤ëª…ë˜ëŠ” ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”."
                "ì¶”ë¡ ì„ í•  ìˆ˜ëŠ” ìˆì§€ë§Œ, extracted JSONì— ì „í˜€ ë“±ì¥í•˜ì§€ ì•ŠëŠ” "
                "ìƒˆë¡œìš´ ë¬¼ì§ˆì´ë‚˜ stepì€ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. "
                "ì…ë ¥ë˜ëŠ” draftëŠ” ë‚´ê°€ ì›í•˜ëŠ” ì¶œë ¥ ì˜¨í†¨ë¡œì§€ í‘œì¤€ ìŠ¤í‚¤ë§ˆë‹¤. "
                "ëª¨ë“  í•„ë“œ(Precursor, InorganicMaterial ë“±)ëŠ” ê°’ê³¼ êµ¬ì¡°ë¥¼ ë‹¨ í•˜ë‚˜ë„ ìˆ˜ì •í•˜ì§€ ë§ê³  draft ê·¸ëŒ€ë¡œ ì¶œë ¥í•  ê²ƒ. "
                "ë‹¨, ì˜¤ì§ SynthesisStep í•„ë“œë§Œ LLMì´ ì¶”ë¡ í•˜ì—¬ usesPrecursor, usesAdditive, usesMedia ë“± ì—°ê²° ì •ë³´ë¥¼ ììœ ë¡­ê²Œ ì±„ì›Œë¼. "
                "SynthesisStepì˜ ê° step ê°ì²´ í‚¤ êµ¬ì¡°ëŠ” draftì™€ ì™„ì „íˆ ì¼ì¹˜ì‹œì¼œì•¼ í•˜ì§€ë§Œ, ê°’ì€ LLMì´ ontology ë° extracted evidenceë¥¼ ê·¼ê±°ë¡œ ì±„ìš´ë‹¤. "
                "SynthesisStep ì´ì™¸ ê·¸ ì–´ë–¤ í•„ë“œ/êµ¬ì¡°ë„ ì¶”ê°€, ì‚­ì œ, ìˆœì„œë³€ê²½, ê°’ìˆ˜ì • í•˜ì§€ ë§ ê²ƒ. "
                "ê°’ì´ í™•ì‹¤ì¹˜ ì•Šìœ¼ë©´ nullì´ë‚˜ ë¹ˆ ë°°ì—´/ê°ì²´ë¡œ ë‚¨ê²¨ë¼."
                "ë‹¹ì‹ ì´ ì •í™•íˆ synthesisstepë‚´ìš©ì„ ì¶”ë¡ í•˜ì§€ ì•Šìœ¼ë©´ ë§ì€ ì‚¬ëŒë“¤ì´ ì£½ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
                "ê·¸ëŸ¬ë‹ˆ ì •í™•íˆ ì¶”ë¡ í•˜ê³  hallucinationì„ ìµœëŒ€í•œ ë°©ì§€í•˜ì„¸ìš”."
            )
        },
        {
            "role": "user",
            "content": json.dumps(user_payload, ensure_ascii=False)
        }
    ]

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0,
        response_format={"type": "json_object"},
        messages=messages
    )

    raw = resp.choices[0].message.content
    try:
        return json.loads(raw)
    except Exception:
        # í˜¹ì‹œ ì½”ë“œë¸”ë¡ì´ë‚˜ ì•ë’¤ í…ìŠ¤íŠ¸ê°€ ë¶™ìœ¼ë©´ best-effort íŒŒì‹±
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1 and end > start:
            return json.loads(raw[start:end+1])
        else:
            raise

def main():
    extracted_path = "data/test.json" #ì›ë³¸ dataê²½ë¡œ 
    ontology_path = "myontology/ontology.json" #ì˜¨í†¨ë¡œì§€ ê²½ë¡œ 
    output_path = "test.json" #ì¶œë ¥í•  íŒŒì¼ ê²½ë¡œ 

    with open(extracted_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if isinstance(data, str):
    # ì´ì¤‘ serialization ë“±ìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë‹¤ì‹œ íŒŒì‹±
     data = json.loads(data)
    if isinstance(data, dict):
        all_extracted = [data]
    elif isinstance(data, list):
        all_extracted = data
    else:
        raise TypeError("Input data is not list/dict.")

    ontology = load_json(ontology_path)
    results = []
    for idx, extracted in enumerate(all_extracted, start=1):
        doi = extracted.get("doi", "NO_DOI")
        print(f"[INFO] ({idx}/{len(all_extracted)}) ë³€í™˜ ì¤‘: ë…¼ë¬¸ DOI = {doi}")
        # 1. ê·œì¹™ ê¸°ë°˜ draft
        draft = fit_extracted_to_ontology(extracted, ontology, idx)
        # 2. LLM ë³´ì •
        refined = llm_refine_with_ontology(extracted, ontology, draft)
        results.append(refined)

    # ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë…¼ë¬¸ID/doi ë“±ê³¼ í•¨ê»˜ ì¶œë ¥
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"[INFO] Saved {len(results)} records to '{output_path}' âœ…")




if __name__ == "__main__":
    main()
