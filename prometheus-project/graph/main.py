#!/usr/bin/env python3
"""
JSON êµ¬ì¡° ë³€í™˜ ë° RDF ë³€í™˜ í†µí•© ìŠ¤í¬ë¦½íŠ¸ (ìµœì¢… ìˆ˜ì • ë²„ì „)
ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ {'extracted': item} í˜•íƒœë¡œ ê°ì‹¸ì„œ ì²˜ë¦¬
"""

from json_to_rdf_converter import JSONtoRDFConverter
from rdf_visualizer import visualize_rdf_graph
from rdf_graph_builder import RDFGraphBuilder
import sys
import os
import json
from collections import Counter


def merge_builders(builders):
    """ì—¬ëŸ¬ RDFGraphBuilderë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©"""
    if not builders:
        return None
    
    # ì²« ë²ˆì§¸ builderë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘
    merged = builders[0]
    
    # ë‚˜ë¨¸ì§€ builderë“¤ì˜ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì¶”ê°€
    for builder in builders[1:]:
        # ë…¸ë“œ ì¶”ê°€ (ì¤‘ë³µ í™•ì¸)
        existing_ids = {node.node_id for node in merged.nodes}
        for node in builder.nodes:
            if node.node_id not in existing_ids:
                merged.nodes.append(node)
                existing_ids.add(node.node_id)
        
        # ì—£ì§€ ì¶”ê°€ (ì¤‘ë³µ í™•ì¸) - ì†ì„±ëª… ìˆ˜ì •: from_nodeâ†’source, relationâ†’edge_type, to_nodeâ†’target
        existing_edges = {(e.source, e.edge_type, e.target) for e in merged.edges}
        for edge in builder.edges:
            edge_tuple = (edge.source, edge.edge_type, edge.target)
            if edge_tuple not in existing_edges:
                merged.edges.append(edge)
                existing_edges.add(edge_tuple)
    
    return merged


def wrap_item_for_converter(item):
    """
    ê° í•­ëª©ì„ converterê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜
    {'InorganicMaterial': [...], 'Precursor': [...]} 
    -> {'extracted': {'InorganicMaterial': [...], 'Precursor': [...]}}
    """
    return {'extracted': item}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("\n" + "="*60)
    print("ğŸ”„ LLM JSON â†’ RDF ê·¸ë˜í”„ ë³€í™˜ê¸° (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬)")
    print("="*60)
    
    # 1. íŒŒì¼ ê²½ë¡œ í™•ì¸
    if len(sys.argv) > 1:
        json_file = sys.argv[1]
    else:
        json_file = "/Users/gamjawon/2025-2-prometheus-14Team/Data/merged_all.json"
        print(f"\nğŸ’¡ ì‚¬ìš©ë²•: python convert_large_json.py <json_file>")
        print(f"   ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {json_file}")
    
    if not os.path.exists(json_file):
        print(f"\nâŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        return
    
    # 2. ì˜¨í†¨ë¡œì§€ íŒŒì¼ í™•ì¸
    ontology_file = "/Users/gamjawon/2025-2-prometheus-14Team/prometheus-project/ontology/aitom_inorganic.rdf"
    if not os.path.exists(ontology_file):
        print(f"\nâŒ ì˜¤ë¥˜: ì˜¨í†¨ë¡œì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ontology_file}")
        return
    
    # 3. ì²˜ë¦¬ ì˜µì…˜ ì…ë ¥
    print(f"\nğŸ“„ JSON íŒŒì¼ ì½ëŠ” ì¤‘: {json_file}")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not isinstance(data, list):
        print("âŒ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
    
    total_items = len(data)
    print(f"ğŸ“¦ ì´ {total_items:,}ê°œ í•­ëª© ë°œê²¬")
    
    # ì²˜ë¦¬í•  í•­ëª© ìˆ˜ ê²°ì •
    print(f"\nâš ï¸  ì£¼ì˜: {total_items:,}ê°œ í•­ëª©ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.")
    print(f"ğŸ’¡ ì˜µì…˜:")
    print(f"   1. ì „ì²´ ì²˜ë¦¬ (ì‹œê°„ ì†Œìš”: ì˜ˆìƒ {total_items//100} ~ {total_items//50}ë¶„)")
    print(f"   2. ìƒ˜í”Œ ì²˜ë¦¬ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)")
    
    choice = input(f"\nì„ íƒ (1=ì „ì²´, 2=ìƒ˜í”Œ, ê¸°ë³¸=ìƒ˜í”Œ): ").strip() or "2"
    
    if choice == "1":
        items_to_process = data
        print(f"\nâœ… ì „ì²´ {len(items_to_process):,}ê°œ í•­ëª© ì²˜ë¦¬")
    else:
        # ìƒ˜í”Œ ê°œìˆ˜ ì…ë ¥
        sample_size = input(f"ìƒ˜í”Œ ê°œìˆ˜ ì…ë ¥ (ê¸°ë³¸=100): ").strip() or "100"
        try:
            sample_size = min(int(sample_size), total_items)
        except:
            sample_size = 100
        items_to_process = data[:sample_size]
        print(f"\nâœ… ì²˜ìŒ {len(items_to_process):,}ê°œ í•­ëª©ë§Œ ì²˜ë¦¬")
    
    # 4. ë³€í™˜ ì‹œì‘
    print(f"\nğŸ”„ ë³€í™˜ ì‹œì‘...\n")
    
    converter = JSONtoRDFConverter(ontology_file=ontology_file)
    all_builders = []
    failed_count = 0
    
    for idx, item in enumerate(items_to_process):
        if (idx + 1) % 100 == 0 or idx == 0 or (idx + 1) == len(items_to_process):
            print(f"ì§„í–‰: {idx+1:,}/{len(items_to_process):,} ({(idx+1)/len(items_to_process)*100:.1f}%)")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (wrapped í˜•íƒœ)
        temp_file = f"temp_item_{idx}.json"
        wrapped_item = wrap_item_for_converter(item)
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(wrapped_item, f, ensure_ascii=False, indent=2)
        
        try:
            builder = converter.convert_json_to_graph(temp_file)
            all_builders.append(builder)
        except Exception as e:
            failed_count += 1
            if failed_count <= 5:  # ì²˜ìŒ 5ê°œ ì—ëŸ¬ë§Œ ì¶œë ¥
                print(f"   âš ï¸  í•­ëª© {idx+1} ì‹¤íŒ¨: {str(e)[:100]}")
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file):
                os.remove(temp_file)
    
    if not all_builders:
        print("\nâŒ ì²˜ë¦¬ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    success_count = len(all_builders)
    print(f"\nâœ… ë³€í™˜ ì™„ë£Œ: {success_count:,}ê°œ ì„±ê³µ, {failed_count:,}ê°œ ì‹¤íŒ¨")
    
    # 5. ê·¸ë˜í”„ ë³‘í•©
    print(f"\nğŸ”„ {len(all_builders):,}ê°œ ê·¸ë˜í”„ ë³‘í•© ì¤‘...")
    builder = merge_builders(all_builders)
    
    # 6. í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    print(f"   ë…¸ë“œ: {len(builder.nodes):,}ê°œ")
    print(f"   ì—£ì§€: {len(builder.edges):,}ê°œ")
    
    # ë…¸ë“œ íƒ€ì…ë³„ ì¹´ìš´íŠ¸
    node_types = Counter(n.node_type for n in builder.nodes)
    print(f"\nğŸ“ˆ ë…¸ë“œ íƒ€ì…ë³„ ë¶„í¬:")
    for node_type, count in node_types.most_common(10):
        print(f"   {node_type}: {count:,}ê°œ")
    if len(node_types) > 10:
        print(f"   ... ì™¸ {len(node_types)-10}ê°œ íƒ€ì…")
    
    # 7. RDF íŒŒì¼ ì €ì¥
    base_name = os.path.basename(json_file).replace('.json', '')
    output_rdf = f"{base_name}_output_{success_count}items.rdf"
    
    print(f"\nğŸ’¾ RDF íŒŒì¼ ì €ì¥ ì¤‘: {output_rdf}")
    builder.save(output_rdf)
    
    # 8. ì‹œê°í™” (ì˜µì…˜)
    output_png = f"{base_name}_graph_{success_count}items.png"
    
    if len(builder.nodes) > 500:
        print(f"\nâš ï¸  ë…¸ë“œê°€ {len(builder.nodes):,}ê°œë¡œ ë„ˆë¬´ ë§ì•„ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"   (ì‹œê°í™”ëŠ” 500ê°œ ì´í•˜ ë…¸ë“œì—ì„œ ê¶Œì¥)")
    else:
        print(f"\nğŸ¨ ê·¸ë˜í”„ ì‹œê°í™” ì¤‘: {output_png}")
        try:
            visualize_rdf_graph(
                output_rdf,
                output_png,
                f"Synthesis Processes ({success_count} items)"
            )
        except Exception as e:
            print(f"âš ï¸  ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    # 9. ì™„ë£Œ ë©”ì‹œì§€
    print("\n" + "="*60)
    print("âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("="*60)
    print(f"\nìƒì„±ëœ íŒŒì¼:")
    print(f"  ğŸ“„ RDF ê·¸ë˜í”„: {output_rdf}")
    if os.path.exists(output_png):
        print(f"  ğŸ–¼ï¸  ì‹œê°í™”:    {output_png}")
    
    # 10. ì¶”ê°€ ì •ë³´
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"  1. RDF íŒŒì¼ í™•ì¸: head -100 {output_rdf}")
    if os.path.exists(output_png):
        print(f"  2. ì‹œê°í™” í™•ì¸:  open {output_png}")
    print(f"  3. ì „ì²´ ì²˜ë¦¬:     python {sys.argv[0]} (ì˜µì…˜ 1 ì„ íƒ)")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()