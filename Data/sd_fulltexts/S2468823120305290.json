{
  "metadata": {
    "title": "Prediction of energies for reaction intermediates and transition states on catalyst surfaces using graph-based machine learning models",
    "authors": "; ; ",
    "journal": "Molecular Catalysis",
    "date": "2020-12-31",
    "doi": "10.1016/j.mcat.2020.111266",
    "abstract": "",
    "uri": "https://api.elsevier.com/content/article/pii/S2468823120305290",
    "pii": "S2468823120305290"
  },
  "fulltext": {
    "full-text-retrieval-response": {
      "scopus-eid": "2-s2.0-85093945121",
      "originalText": "serial JL 315758 291210 291744 291790 291809 31 Molecular Catalysis MOLECULARCATALYSIS 2020-10-24 2020-10-24 2020-10-24 2020-10-24 2020-12-06T07:55:27 1-s2.0-S2468823120305290 S2468-8231(20)30529-0 S2468823120305290 10.1016/j.mcat.2020.111266 S300 S300.1 FULL-TEXT 1-s2.0-S2468823120X00174 2020-12-06T08:12:58.773678Z 0 0 20201201 20201231 2020 2020-10-24T05:21:58.473261Z absattachment articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst primabst ref specialabst 2468-8231 24688231 true 498 498 C Volume 498 19 111266 111266 111266 202012 December 2020 2020-12-01 2020-12-31 2020 Regular Papers article fla © 2020 Elsevier B.V. All rights reserved. PREDICTIONENERGIESFORREACTIONINTERMEDIATESTRANSITIONSTATESCATALYSTSURFACESUSINGGRAPHBASEDMACHINELEARNINGMODELS WANG B Introduction Methods Dataset Feature extraction and machine learning methods implementation Training and test process Results and discussion Energy prediction with individual models Graph convolutions Weave Graph neural network Model ensemble General discussion and outlook Effectiveness of transition state representation approach Comparison with BEP relations for activation energy prediction Outlook Conclusions CRediT authorship contribution statement Acknowledgements Appendix A Supplementary data References SEGLER 2018 604 M WANG 2019 30389 30397 B GU 2020 T YANG 2014 182 186 B LOFFREDA 2009 9140 9142 D BLIGAARD 2004 206 217 T FERRIN 2009 5809 5815 P VOJVODIC 2011 244509 A YANG 2013 15244 15250 B WU 2016 21720 21729 P FERNANDEZ 2008 4683 4686 E JONES 2011 6318 6323 G ABILDPEDERSEN 2007 016105 F GREELEY 2016 605 635 J WANG 2017 4024 4033 K YANG 2017 1508 1514 B WANG 2018 1493 1499 P LIU 2019 9876 9882 H XU 2018 339 348 H XU 2017 2164 2170 H XU 2018 9702 9710 H CHEN 2020 3074 3083 S YANG 2020 890 895 K XIN 2012 12 16 H MA 2015 3528 3533 X XIN 2012 376 390 H HOLEWINSKI 2013 312 319 A WANG 2019 502 504 S LI 2017 24131 24138 Z LI 2017 232 238 Z SMITH 2017 3192 3203 J MA 2015 263 274 J BREDEL 2004 262 275 M TSUBAKI 2018 309 318 M WEININGER 1988 31 36 D BEHLER 2007 146401 J BARTOK 2013 184115 A HUANG 2017 6327 6337 S JINNOUCHI 2017 4279 4283 R JAGER 2018 37 M GLEM 2006 199 204 R ROGERS 2010 742 754 D COHEN 1993 2419 2438 N SALCICCIOLI 2012 1873 1886 M VOROTNIKOV 2015 10417 10426 V ULISSI 2017 14621 Z CHOWDHURY 2018 28142 28150 A WU 2018 513 530 Z KEARNES 2016 595 608 S MEDFORD 2015 794 807 A RAMSUNDAR 2019 B SRIVASTAVA 2014 N IOFFE 2015 448 456 S OPITZ 1999 169 198 D TINKAM 1998 832 844 H BREIMAN 2001 5 32 L LI 2019 6882 6894 X WANGX2020X111266 WANGX2020X111266XB 2022-10-24T00:00:00.000Z 2022-10-24T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2020 Elsevier B.V. All rights reserved. 2020-10-22T01:27:06.494Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/eoas NSFC National Natural Science Foundation of China http://data.elsevier.com/vocabulary/SciValFunders/501100001809 http://sws.geonames.org/1814991 STCSM Science and Technology Commission of Shanghai Municipality http://data.elsevier.com/vocabulary/SciValFunders/501100003399 http://sws.geonames.org/1814991 item S2468-8231(20)30529-0 S2468823120305290 1-s2.0-S2468823120305290 10.1016/j.mcat.2020.111266 315758 2020-12-06T08:12:58.773678Z 2020-12-01 2020-12-31 1-s2.0-S2468823120305290-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/MAIN/application/pdf/26324c03bdfd577f53ed94b592042d7b/main.pdf main.pdf pdf true 3685174 MAIN 7 1-s2.0-S2468823120305290-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/PREVIEW/image/png/cb62294a4eb11dc17e92b3ff33f45c3c/main_1.png main_1.png png 56482 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2468823120305290-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr4/DOWNSAMPLED/image/jpeg/0c0bf07584e077709d6ed9c8571ac590/gr4.jpg gr4 gr4.jpg jpg 40096 303 679 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr3/DOWNSAMPLED/image/jpeg/8bc920fb09ca16aba29aef5c5ad39e77/gr3.jpg gr3 gr3.jpg jpg 106391 798 679 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr6/DOWNSAMPLED/image/jpeg/3224dafed49911b50e567718b5be14cf/gr6.jpg gr6 gr6.jpg jpg 28492 268 340 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr5/DOWNSAMPLED/image/jpeg/a4fd2c5a0e52477eecaa44685715c664/gr5.jpg gr5 gr5.jpg jpg 48443 209 679 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr2/DOWNSAMPLED/image/jpeg/256b8b61e0ebbed9e012c769549fa998/gr2.jpg gr2 gr2.jpg jpg 27550 194 717 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-ga1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/ga1/DOWNSAMPLED/image/jpeg/44c0ac58ad08af8e2373f51afcf52c86/ga1.jpg ga1 true ga1.jpg jpg 17362 200 260 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr1/DOWNSAMPLED/image/jpeg/7f614ac1c4d6ccb209e38cf433ed11cb/gr1.jpg gr1 gr1.jpg jpg 19597 271 340 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-sc1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/sc1/DOWNSAMPLED/image/jpeg/56c1b4510a2998cb8ba561aa61e6b0ba/sc1.jpg sc1 sc1.jpg jpg 26640 167 679 IMAGE-DOWNSAMPLED 1-s2.0-S2468823120305290-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr4/THUMBNAIL/image/gif/112832e8faa081d56c45ff51d884c8be/gr4.sml gr4 gr4.sml sml 6672 98 219 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr3/THUMBNAIL/image/gif/c299c4dda39f0ddaca190a9192b25f38/gr3.sml gr3 gr3.sml sml 8014 163 139 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr6/THUMBNAIL/image/gif/e10754285031992ab9baff6f615f7500/gr6.sml gr6 gr6.sml sml 11377 164 208 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr5/THUMBNAIL/image/gif/386a8720ca6936e8c37d23958afcd605/gr5.sml gr5 gr5.sml sml 8990 68 219 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr2/THUMBNAIL/image/gif/fa5be45ac0e69abf4c48cacc0354f1ad/gr2.sml gr2 gr2.sml sml 4091 59 219 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-ga1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/ga1/THUMBNAIL/image/gif/214eec43226806751458dfedf38847c7/ga1.sml ga1 true ga1.sml sml 15179 164 213 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/gr1/THUMBNAIL/image/gif/a6af70e471f2965609b34673a681d043/gr1.sml gr1 gr1.sml sml 10112 164 205 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-sc1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/sc1/THUMBNAIL/image/gif/04ec250ac46da6f851884150f490d7de/sc1.sml sc1 sc1.sml sml 4727 54 219 IMAGE-THUMBNAIL 1-s2.0-S2468823120305290-mmc1.docx https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2468823120305290/mmc1/MAIN/application/vnd.openxmlformats-officedocument.wordprocessingml.document/ccdb921521bcd302567489e1f26afb9b/mmc1.docx mmc1 mmc1.docx docx 771983 APPLICATION 1-s2.0-S2468823120305290-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10LXV53GWMW/MAIN/application/pdf/1e92b2776b671ea79c12940ea1939466/am.pdf am am.pdf pdf false 774894 AAM-PDF MCAT 111266 111266 S2468-8231(20)30529-0 10.1016/j.mcat.2020.111266 Elsevier B.V. Fig. 1 Distribution of the DFT-calculated formation energies of 315 C1/C2 adsorbates and transition states on Rh(111) with respect to the energies of gaseous CO, H2 and CH4. Fig. 1 Fig. 2 Loss in the training process of different models as a function of transiting epochs. Fig. 2 Fig. 3 Parity plot between the predicted energies of surface species and those calculated with DFT (left column); and error distribution of different models (right column) on training set (yellow) and test set (blue). Fig. 3 Fig. 4 Parity plot between the predicted energies of surface species within the test set and those calculated with DFT. The corresponding RMSEs of different models are listed in Table 1. Fig. 4 Fig. 5 Distribution of the mean value and standard deviation in the energy prediction for surface intermediates and transition states of different dataset using different machine learning models. Fig. 5 Fig. 6 Parity plot between DFT calculated activation energy and those predicted with graph neural network and BEP relation. Fig. 6 Scheme 1 Procedure of graph-based machine learning for the prediction of surface species energies. E ads and E TS are the energies of surface adsorbates and transition states, respectively. E pred and E DFT are the machine-learning-predicted and DFT energies, respectively. Scheme 1 Table 1 Summary of RMSE and MAE (both in eV) of predicted energies of surface species on test set using different machine learning models. Table 1 Method Graph convolutions Weave Graph neural network Ensemble– median Ensemble– mean RMSE 0.22 0.27 0.23 0.20 0.19 MAE 0.18 0.21 0.18 0.15 0.15 Prediction of energies for reaction intermediates and transition states on catalyst surfaces using graph-based machine learning models Baochuan Wang Investigation Data curation Formal analysis Writing - original draft Tangjie Gu Data curation Writing - review & editing Yijun Lu Formal analysis Writing - review & editing Bo Yang Conceptualization Supervision Funding acquisition Project administration Resources Writing - review & editing * School of Physical Science and Technology, ShanghaiTech University, 393 Middle Huaxia Road, Shanghai 201210, China School of Physical Science and Technology ShanghaiTech University 393 Middle Huaxia Road Shanghai 201210 China School of Physical Science and Technology, ShanghaiTech University, 393 Middle Huaxia Road, Shanghai 201210, China ⁎ Corresponding author: Graphical abstract Computational studies of heterogeneous catalysis processes depend on massive electronic structure calculations to obtain the energies of intermediates and transition states. To speed up this process, several machine-learning-based methods were proposed for the prediction of surface species energies. Here we developed a new method to represent all surface species with molecular graph, a data structure which is easy to read and extendable, but seldom utilized in catalysis studies. The molecular graph dataset consists of 315 C1/C2 surface intermediates and transition states on Rh(111), which are all possible intermediates in the complex reaction network of ethanol synthesis from syngas. Three recently proposed graph-based machine learning methods, namely graph convolutions, weave and graph neural network, were employed to train models and predict the energies from molecular graphs. Furthermore, two ensemble models combining the abovementioned models were built, using which the best RMSE and MAE reaches 0.19 and 0.15 eV, respectively. In addition, error of activation energies predicted with graph neural network was compared with that predicted using traditional BEP relations, and error of the prediction for surface intermediate energies and transition state energies were compared. Finally, possible directions of using the developed methods in extendable energy predictions were suggested and discussed. Keywords Machine learning Molecular graph Energy prediction Surface species BEP relation Introduction Complexity of reaction network and the presence of a large number of species in heterogeneous catalysis processes make the efficient and rational computational design of catalysts rather challenging. Experimentally, one can predict the possible reaction pathways using a similar approach developed in organic synthesis, where the Monte Carlo tree search and neural network were used, [1] given that the information of each reaction step can be obtained. Alternatively, the complexity of surface reaction network can be reduced by using the computational approach developed recently by our group through network pruning iteratively [2,3], whereas the energy calculation for the species involved in reaction networks is still time-consuming. For instance, the transformation of syngas (CO and H2) to C1 or C2 products contains hundreds of possible reaction intermediates and thousands of reaction pathways, and normally expensive density functional theory (DFT) is used to calculate the energies of these intermediates to arrive at a convincing conclusion. This process, including the construction of surface intermediate structures, the structural optimization of these species and the search of transition states, could take months. To achieve efficient theoretical catalyst screening, a method for fast predicting the energies of new species should be developed. In heterogeneous catalysis studies, several data-driven-like methods, such as “Brønsted–Evans–Polanyi (BEP) relations” [4–10] or “scaling relations” [11–18], have been proposed to predict energy of intermediates and transition states. In addition, designing proper “descriptors” using easily accessible features, such as electronic properties, physical characteristics and structural features to predict the adsorption energies of key species or activity and selectivity of a certain reaction for catalyst screening, is attracting considerable attentions. [19–30] Recently, as the development of machine learning and deep learning algorithms, several new data-driven methods were proposed in computational chemistry, bioinformatics and other similar fields, and showed great potential in these studies [1,31–34]. An ideal model for predicting energies of species on surface to replace expensive DFT calculations should be extendable between different species with sufficient accuracy, e.g. the model trained based on C1/C2 energy dataset from DFT calculations should be able to predict energies of C3, C4 or even larger species. One can imagine that developing such methods is rather challenging and practically relies on well-defined data structures that are able to capture the internal feature of each surface species. Two typical data structures that can be considered are 3D structures and molecular graphs. 3D structures are widely used in computational chemistry studies including the structural optimization with DFT, where each (x, y, z) coordinate is utilized to indicate the position of an atom. While molecular graph represents the atom as one “node” and the bond as one “edge” in each species following the graph theory, it ignores the change of structure within a species. The key feature of different species can be better captured with molecular graph, and the transformation of species are also much easier to be implemented. Simplified molecular input line entry system, known as SMILES, [35] is widely used to represent the species based on molecular graph. Feature extraction from the 3D structures or molecular graphs is also required for further machine learning model training. Symmetry function [36] and Smooth Overlap of Atomic Positions (SOAP) [37] are two commonly used feature extraction methods for 3D structure data in catalysis field to train neural network models for the prediction of potential energy surface for catalysts screening [38] or adsorption energy at different sites [39,40]. For molecular graphs or SMILES data, feature extraction methods including circular fingerprints [41] and extended-connectivity fingerprints (ECFP) [42] method can be used upon definition of “fingerprints”, the subgraphs of a molecular graph. Similar methods such as group additivity [43–46] and bag of bonds [47] were also proposed for energy predictions in catalysis studies. In the current work, we are aiming at using extendable graph-based machine learning models to predict energies of surfaces species. 315 C1/C2 intermediates and transition states in the reaction network of ethanol synthesis from syngas on Rh(111) were selected. [3] In the algorithm developed recently by our group, these surface intermediates and transition states were generated in the form of molecular graphs. Three recently proposed graph-based methods, i.e. graph convolutions [48,49], weave [48,49] and graph neural network [34], were applied to train machine learning models for energy prediction. Subsequently, two ensemble models combining the results obtained from the abovementioned three methods were used in order to further reduce the prediction error. In the machine learning process, the dataset of 315 species was split into training set (80 %) and test set (20 %), followed by hyper parameter tuning using 5-fold cross validation on training set. Methods The machine learning process in this work can be divided into the following four steps, as shown in Scheme 1 : (i) build a dataset from database; (ii) extract features to a form of vector which is compatible with operations in machine learning algorithms; (iii) machine learning model training and hyper parameter tuning according to the performance of cross validation on training set; (iv) evaluate the models using test set. In the following sections, details of these processes for the extendable prediction of energies of species on Rh(111) using graph-based models will be introduced. Dataset Here 315 species (including transition states) on Rh(111) with optimized structures and energies calculated with DFT and the BEEF-vdW functional were used. It should be mentioned that some species may have various possible structures or locate at different sites on surface, here only the information of the most stable one was recorded. The molecular graphs were obtained from the optimized structures of these surface species after removing the metal atoms, then stored with RDKit. [50] During this process, all bonds were considered as single bonds. However, taking the elementary reaction of CH* + CHO*→CHCHO* as an example, one problem may arise here that it is difficult to differentiate the transition state, noted as CH−CHO*, from the product CHCHO* in the form of molecular graph. Therefore, here the connection between two reacting parts at transition state were treated as a “virtual bond” in the molecular graph, as shown in Scheme 1 as a dashed line. The effectiveness of such approach will be discussed later. Molecular graphs obtained for all these species are shown in the Supporting Information (SI) as Figure S1. We used the formation energy of these species, which can be calculated with CatMAP [51], for model training instead of the raw electronic energy obtained from DFT calculations. The corresponding formation energies with respect to the energies of gaseous CO, H2 and CH4 are listed in Table S1 of the SI. Fig. 1 shows the distribution of the formation energies of 315 species, which are in the range of -3.2 eV–2.3 eV and show a mean value of -0.34 eV, a standard deviation of 1.07 eV and a skewness of -0.035 eV, indicating that the data can be considered following a proper normal distribution for further machine learning model training. Feature extraction and machine learning methods implementation Machine learning models usually need a feature in the form of vector or matrix for further predictions, and the shape of vector or matrix should keep identical in all samples. Here in our work, we used three recently proposed methods, i.e. graph convolutions [48,49], weave [48,49] and graph neural network [34], to perform feature extraction and energy regression based on the molecular graphs generated. Graph convolutions offers each atom with an initial feature vector and a neighbor list to represent the local chemical environment of atoms. Weave is similar to graph convolutions but the neighbor listing is replaced by more detailed pair features [48]. In addition, the graph neural network method used in this work embeds r-radius subgraphs of each molecular graph and uses vertex and edge transitions to propagate the feature, and the final prediction can be obtained by taking the summation. [34] For the implement of the graph convolutions and weave methods, an open-source tool Deepchem [52] was used for feature extraction and building the corresponding neural network models. Graph neural network was implemented by using the tools developed by Tsubaki et al. [34]. Training and test process The dataset was split into training set (80 %) and test set (20 %), and the training set and test set were kept the same when each machine learning method was used. The whole process was divided into tuning stage and test stage, as shown in Figure S2. In the tuning stage, we used 5-fold cross validation method with grid search to tune the hyper parameters in the model. The candidate parameters were obtained firstly from the default parameters used in the works proposing these methods, and then some initial parameters were set based on the size of data sets. We also made some pretests for the boundary values of these parameters, and those parameters leading to unreasonable RMSEs were discarded. Specifically, the training set was split to five equal folds, each time we chose one of them as validation set and the remaining four folds were considered as training set to train the model. Upon obtaining the error for all folds, the final validation error is the average of them. Then hyper parameter such as the size of hidden layer, learning rate and batch size were tuned using grid search, where validation error on all candidate parameters were obtained and the parameter with the lowest error were selected. After the tuning stage, the model with the optimal hyper parameters was used for the training and testing. Results and discussion Energy prediction with individual models Graph convolutions The hyper parameters considered in the graph convolutions method are listed in Table S2, where batch size, graph convolutions layer structure, learning rate and dropout were tuned using grid search, and the optimal values are highlighted in bold. Batch size and learning rate are hyper parameters in the training process of neural network. Graph convolutions layer structure means the layer structure of neural network, e.g., 128−64 means a two-layer neural network, where size of the first and second layer is 128 and 64, respectively. Dropout is a method to prevent neural network model from overfitting by temporarily removing some units from the network. [53] Regarding the size of atom features in graph convolutions method, we used the default value of 75 in DeepChem, which consists of one-hot coding of 44 atom types, 11 status of connection to other atoms, 7 types of implicit valence, 5 types of hybridization, 5 possible number of hydrogen atoms from 0 to 4, formal charge, number of radical charges and status of aromaticity. The number of training epochs was chosen according to the loss of the model during the training process, as shown in Fig. 2 , where batch size, graph convolutions layer structure, learning rate and dropout is 16,128−64, 0.001 and 0.4, respectively. One can find from Fig. 2 that the loss becomes converged after 200th epoch. In order to make the model easy to converge on other conditions, the training epoch was set to 300. The table of grid search results, which shows the error of cross validation on different hyper parameters, is shown in the SI, and the cross validation root-mean-squared error (RMSE) on best hyper parameter is 0.38 eV. Using the best hyper parameter tuned by grid search after training the model on training set, the final prediction on test set is shown in Fig. 3 , where the RMSE is 0.22 eV. Weave The hyper parameters used in the weave method are shown in Table S3, where batch size, hidden layer size, size of graph features, learning rate and dropout were tuned using grid search and the optimal value is highlighted in bold. Similar with the graph convolutions method, the size of atom features implemented by DeepChem were set to 75 and no additional features added. The size of pair features were set to 14, which consists of 6 bond types, 7 status of graph distance and the status of whether the atoms in the pair are in the same ring. [49] Similarly, training epochs was set to 300, according to the loss of model during the training process shown in Fig. 2, where batch size, hidden layer size, size of graph features, learning rate and dropout is 16, 64, 128, 0.001 and 0.4, respectively,. The table of grid search results is also shown in the SI, and the cross validation RMSE on best hyper parameter is 0.32 eV. Using the best hyper parameter tuned by grid search after training the model on training set, the final prediction on test set is shown in Fig. 3, where the RMSE is 0.27 eV. It should be mentioned that the weave method was found to suffer from overfitting while training the models, resulting in significantly low RMSE of 0.023 eV. Graph neural network In graph neural network, the fingerprint was extracted using a radius of 1, meaning that each centering atom forms a fingerprint with the nearest one neighbor. Severe overfitting was observed using higher radius, because the size of features is too large for these 315 samples. Batch normalization [54] layers were added after each hidden and output layer to prevent the overfitting observed during the training process. Hyper parameters of the graph neural network method are listed in Table S4, where batch size, size of features in hidden layers, size of hidden layers and learning rate were tuned using grid search and the optimal values were highlighted in bold in the table. The neural network model consists of several hidden layers and output layers. For example, a group of hyper parameter where size of features is 64, size of hidden layers is 4 and size of output layers is 2 forms a neural network with a structure of input-hidden(64−64-64−64)-output(64−64). Default values of learning rate decay were used in the training process, where learning rate decays every 10 iterations by multiplying the last learning rate by 0.99. Other parameters are all set to default values. Same to the other two methods, training epochs were set to 300, according to the loss of model during training process shown in Fig. 2, where batch size, size of features, size of hidden layers and learning rate is 16, 64, 16 and 0.001, respectively. The table of grid search results is shown in the SI, and the cross validation RMSE based on the optimal hyper parameter is 0.13 eV. Using the best hyper parameter tuned by grid search after training the model on training set, the final prediction on test set showed an RMSE of 0.23 eV, as one can find from Fig. 3. Model ensemble Ensemble learning methods, e.g. bagging and boosting, were found capable of outperforming a single model [55]. One can make an ensemble either from different models trained on subsets of features with the random subspace method [56], or from models trained on different data sampled from training set with random forests [57]. In the current work, we have trained 3 independent models, each with a unique feature extracting method and neural network model. A reasonable assumption is that the prediction of these independent models forms a normal distribution, where the mean is close to the true value. Based on this assumption, we made the abovementioned 3 original models to two ensemble models, namely ensemble–median and ensemble–mean. In the two ensemble models, we first collect the prediction of the three original models, and then use the mean or median value of the predictions for each species as the final prediction of the ensemble model. As one can find from Table 1 , the RMSE of ensemble–mean and ensemble–median on test set is 0.19 eV and 0.20 eV, respectively. Fig. 4 shows the parity plot of prediction results on test set of three original models and the two ensemble models. In the models we used, graph convolutions model with a RMSE of 0.22 eV performs slightly better than the other two models. Two ensemble models outperform all of them, the best one made a prediction with only a RMSE of 0.19 eV. The MAE obtained in the current work is similar to that reported recently with combined representations for energy prediction in C2 alcohol reforming reactions, where only surface adsorbates were considered [58]. General discussion and outlook Effectiveness of transition state representation approach In the current work, we used a virtual bond in the molecular graph for transition states to indicate the formation or breaking of the bond in elementary reactions. In order to verify this approach, the distribution of error in prediction of intermediates and transition states of different dataset and machine learning models are plotted in Fig. 5 . One can find from this figure that the mean value and standard deviation of the predicted results for transition states are almost identical to those for surface intermediates, especially for the predictions based on test set. Therefore, we believe that the approach of “virtual bond” is an effective feature for generating the molecular graph of transition states on catalyst surfaces. Comparison with BEP relations for activation energy prediction The estimation of activation energies from reaction energies can be carried out using BEP relations, which is a common method in computational catalysis studies. Here we predicted activation energy directly from the species energy predicted by graph neural network and compared with results of BEP relations. The constructed BEP relation was shown in Figure S3 of the SI. It should be mentioned that, for the activation energy prediction, we only considered results obtained from graph neural network method because the training and test RMSE is similar to results of ensemble models, and the predictions of both training and test set, and DFT energy of C, O and H is added. The parity plot between DFT calculated activation energy and those predicted with graph neural network and BEP relation is shown in Fig. 6 . Graph neural network method obtained RMSE of 0.23, lower than the RMSE of 0.35 eV by linear scaling relations. The method developed in this work outperforms existing linear scaling relations method on the data set including DRM and C2 synthesis, although more works need to be done to verify the transferability of these graph based methods. More importantly, linear scaling relations method needs further calculations of reaction energies to estimate the activation energies, but graph-based method no longer requires DFT calculations once the model is well trained. Outlook These graph-based models can be rather useful in catalysis field. It can be used to predict energies of new species with atoms and bond types shown in training set, which would be very helpful for the further studies on complex reaction network with massive intermediates and transition states. This would provide a basis to at least rule out some intermediates with high energies in the complex reaction network. In addition, the feature vector of molecular graph can be concatenated with surface or site features to predict energies of different species on different surfaces or sites. Conclusions In this work, we first generated a dataset consisting of the molecular graphs of C1/C2 intermediates and transition states on surface with a new approach developed, for the purpose of extendable energy prediction of surface species with different sizes. Subsequently, three graph-based models, i.e. graph convolutions, weave and graph neural network, were trained and hyper parameters were tuned for predicting energies of these species, resulting in a RMSE of 0.22 eV, 0.27 eV and 0.23 eV on test set, respectively. Furthermore, two ensemble models were built using median and mean of the predictions of these models and they outperform the three original models, resulting in a RMSE of 0.20 eV and 0.19 eV, respectively. Further analysis indicated that the prediction errors for the energies of intermediate and transitions states are similar, suggesting the “virtual” bond approach in transition state representation is effective. In addition, the prediction error while using graph neural network is much lower than that derived from existing linear scaling relations method, e.g. BEP relation. Future applications of the models developed here would include the energy predictions of surface species with more atoms on the same surface or even different metal surfaces through adding the features of metals or surface sites into graph-based machine learning models. CRediT authorship contribution statement Baochuan Wang: Investigation, Data curation, Formal analysis, Writing - original draft. Tangjie Gu: Data curation, Writing - review & editing. Yijun Lu: Formal analysis, Writing - review & editing. Bo Yang: Conceptualization, Supervision, Funding acquisition, Project administration, Resources, Writing - review & editing. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements This work was supported by Shanghai Rising-Star Program (20QA1406800), the National Natural Science Foundation of China (91745102) and ShanghaiTech University. We thank the HPC Platform of ShanghaiTech University and Shanghai Supercomputer Center for computing time. Appendix A Supplementary data Supplementary material related to this article can be found, in the online version, at doi:https://doi.org/10.1016/j.mcat.2020.111266. Appendix A Supplementary data The following is Supplementary data to this article: References [1] M.H.S. Segler M. Preuss M.P. Waller Planning chemical syntheses with deep neural networks and symbolic AI Nature 555 2018 604 M.H.S. Segler, M. Preuss, M.P. Waller, Planning chemical syntheses with deep neural networks and symbolic AI, Nature, 555 (2018) 604. [2] B. Wang S. Chen J. Zhang S. Li B. Yang Propagating DFT Uncertainty to Mechanism Determination, Degree of Rate Control, and Coverage Analysis: The Kinetics of Dry Reforming of Methane J. Phys. Chem. C 123 2019 30389 30397 B. Wang, S. Chen, J. Zhang, S. Li, B. Yang, Propagating DFT Uncertainty to Mechanism Determination, Degree of Rate Control, and Coverage Analysis: The Kinetics of Dry Reforming of Methane, J. Phys. Chem. C, 123 (2019) 30389-30397. [3] T. Gu B. Wang S. Chen B. Yang Automated generation and analysis of the complex catalytic reaction network of ethanol synthesis from syngas on Rh(111) ACS Catal. 2020 10.1021/acscatal.1020c00630 T. Gu, B. Wang, S. Chen, B. Yang, Automated Generation and Analysis of the Complex Catalytic Reaction Network of Ethanol Synthesis from Syngas on Rh(111), ACS Catal., (2020) 10.1021/acscatal.1020c00630. [4] B. Yang R. Burch C. Hardacre G. Headdock P. Hu Understanding the optimal adsorption energies for catalyst screening in heterogeneous catalysis ACS Catal. 4 2014 182 186 B. Yang, R. Burch, C. Hardacre, G. Headdock, P. Hu, Understanding the Optimal Adsorption Energies for Catalyst Screening in Heterogeneous Catalysis, ACS Catal., 4 (2014) 182-186. [5] D. Loffreda F. Delbecq F. Vigné P. Sautet Fast prediction of selectivity in heterogeneous catalysis from extended brønsted–evans–polanyi relations: a theoretical insight Angew. Chem. 121 2009 9140 9142 D. Loffreda, F. Delbecq, F. Vigné, P. Sautet, Fast Prediction of Selectivity in Heterogeneous Catalysis from Extended Brønsted–Evans–Polanyi Relations: A Theoretical Insight, Angew. Chem., 121 (2009) 9140-9142. [6] T. Bligaard J.K. Nørskov S. Dahl J. Matthiesen C.H. Christensen J. Sehested The Brønsted–Evans–Polanyi relation and the volcano curve in heterogeneous catalysis J. Catal. 224 2004 206 217 T. Bligaard, J.K. Nørskov, S. Dahl, J. Matthiesen, C.H. Christensen, J. Sehested, The Brønsted–Evans–Polanyi relation and the volcano curve in heterogeneous catalysis, J. Catal., 224 (2004) 206-217. [7] P. Ferrin D. Simonetti S. Kandoi E. Kunkes J.A. Dumesic J.K. Nørskov M. Mavrikakis Modeling ethanol decomposition on transition metals: a combined application of scaling and brønsted−Evans−Polanyi relations J. Am. Chem. Soc. 131 2009 5809 5815 P. Ferrin, D. Simonetti, S. Kandoi, E. Kunkes, J.A. Dumesic, J.K. Nørskov, M. Mavrikakis, Modeling Ethanol Decomposition on Transition Metals: A Combined Application of Scaling and Brønsted−Evans−Polanyi Relations, J. Am. Chem. Soc., 131 (2009) 5809-5815. [8] A. Vojvodic F. Calle-Vallejo W. Guo S. Wang A. Toftelund F. Studt J.I. Martínez J. Shen I.C. Man J. Rossmeisl T. Bligaard J.K. Nørskov F. Abild-Pedersen On the behavior of Brønsted-Evans-Polanyi relations for transition metal oxides J. Chem. Phys. 134 2011 244509 A. Vojvodic, F. Calle-Vallejo, W. Guo, S. Wang, A. Toftelund, F. Studt, J.I. Martínez, J. Shen, I.C. Man, J. Rossmeisl, T. Bligaard, J.K. Nørskov, F. Abild-Pedersen, On the behavior of Brønsted-Evans-Polanyi relations for transition metal oxides, J. Chem. Phys., 134 (2011) 244509. [9] B. Yang X.-Q. Gong H.-F. Wang X.-M. Cao J.J. Rooney P. Hu Evidence to challenge the universality of the horiuti-polanyi mechanism for hydrogenation in heterogeneous catalysis: origin and trend of the preference of a non-horiuti-Polanyi mechanism J. Am. Chem. Soc. 135 2013 15244 15250 B. Yang, X.-Q. Gong, H.-F. Wang, X.-M. Cao, J.J. Rooney, P. Hu, Evidence To Challenge the Universality of the Horiuti-Polanyi Mechanism for Hydrogenation in Heterogeneous Catalysis: Origin and Trend of the Preference of a Non-Horiuti-Polanyi Mechanism, J. Am. Chem. Soc., 135 (2013) 15244-15250. [10] P.P. Wu B. Yang Theoretical insights into the promotion effect of subsurface boron for the selective hydrogenation of CO to methanol over Pd catalysts Phys. Chem. Chem. Phys. 18 2016 21720 21729 P.P. Wu, B. Yang, Theoretical insights into the promotion effect of subsurface boron for the selective hydrogenation of CO to methanol over Pd catalysts, Phys. Chem. Chem. Phys., 18 (2016) 21720-21729. [11] E.M. Fernández P.G. Moses A. Toftelund H.A. Hansen J.I. Martínez F. Abild-Pedersen J. Kleis B. Hinnemann J. Rossmeisl T. Bligaard J.K. Nørskov Scaling relationships for adsorption energies on transition metal oxide, sulfide, and nitride surfaces Angew. Chem. Int. Ed. 47 2008 4683 4686 E.M. Fernández, P.G. Moses, A. Toftelund, H.A. Hansen, J.I. Martínez, F. Abild-Pedersen, J. Kleis, B. Hinnemann, J. Rossmeisl, T. Bligaard, J.K. Nørskov, Scaling Relationships for Adsorption Energies on Transition Metal Oxide, Sulfide, and Nitride Surfaces, Angew. Chem. Int. Ed., 47 (2008) 4683-4686. [12] G. Jones F. Studt F. Abild-Pedersen J.K. Nørskov T. Bligaard Scaling relationships for adsorption energies of C2 hydrocarbons on transition metal surfaces Chem. Eng. Sci. 66 2011 6318 6323 G. Jones, F. Studt, F. Abild-Pedersen, J.K. Nørskov, T. Bligaard, Scaling relationships for adsorption energies of C2 hydrocarbons on transition metal surfaces, Chem. Eng. Sci., 66 (2011) 6318-6323. [13] F. Abild-Pedersen J. Greeley F. Studt J. Rossmeisl T.R. Munter P.G. Moses E. Skúlason T. Bligaard J.K. Nørskov Scaling Properties of Adsorption Energies for Hydrogen-Containing Molecules on Transition-Metal Surfaces Phys. Rev. Lett. 99 2007 016105 F. Abild-Pedersen, J. Greeley, F. Studt, J. Rossmeisl, T.R. Munter, P.G. Moses, E. Skúlason, T. Bligaard, J.K. Nørskov, Scaling Properties of Adsorption Energies for Hydrogen-Containing Molecules on Transition-Metal Surfaces, Phys. Rev. Lett., 99 (2007) 016105. [14] J. Greeley Theoretical heterogeneous catalysis: scaling relationships and computational catalyst design Annu. Rev. Chem. Biomol. Eng. 7 2016 605 635 J. Greeley, Theoretical Heterogeneous Catalysis: Scaling Relationships and Computational Catalyst Design, Annu. Rev. Chem. Biomol. Eng., 7 (2016) 605-635. [15] K.L. Wang B. Yang Theoretical understandings on the selectivity of acrolein hydrogenation over silver surfaces: non-horiuti-Polanyi mechanism is the key Catal. Sci. Technol. 7 2017 4024 4033 K.L. Wang, B. Yang, Theoretical Understandings on the Selectivity of Acrolein Hydrogenation over Silver Surfaces: Non-Horiuti-Polanyi Mechanism is the Key, Catal. Sci. Technol., 7 (2017) 4024-4033. [16] B. Yang R. Burch C. Hardacre P. Hu P. Hughes Selective hydrogenation of acetylene over Cu(211), Ag(211) and Au(211): horiuti-Polanyi mechanism vs. Non-Horiuti-Polanyi mechanism Catal. Sci. Technol. 7 2017 1508 1514 B. Yang, R. Burch, C. Hardacre, P. Hu, P. Hughes, Selective hydrogenation of acetylene over Cu(211), Ag(211) and Au(211): Horiuti-Polanyi mechanism vs. non-Horiuti-Polanyi mechanism, Catal. Sci. Technol., 7 (2017) 1508-1514. [17] P. Wang B. Yang Influence of surface strain on activity and selectivity of Pd-based catalysts for the hydrogenation of acetylene: a DFT study Chin. J. Catal. 39 2018 1493 1499 P. Wang, B. Yang, Influence of surface strain on activity and selectivity of Pd-based catalysts for the hydrogenation of acetylene: A DFT study, Chin. J. Catal., 39 (2018) 1493-1499. [18] H. Liu J. Liu B. Yang Modeling the effect of surface CO coverage on the electrocatalytic reduction of CO2 to CO on Pd surfaces Phys. Chem. Chem. Phys. 21 2019 9876 9882 H. Liu, J. Liu, B. Yang, Modeling the effect of surface CO coverage on the electrocatalytic reduction of CO2 to CO on Pd surfaces, Phys. Chem. Chem. Phys., 21 (2019) 9876-9882. [19] H. Xu D. Cheng D. Cao X.C. Zeng A universal principle for a rational design of single-atom electrocatalysts Nat. Catal. 1 2018 339 348 H. Xu, D. Cheng, D. Cao, X.C. Zeng, A universal principle for a rational design of single-atom electrocatalysts, Nat. Catal., 1 (2018) 339-348. [20] H. Xu D. Cheng Y. Gao Design of high-performance Pd-Based alloy nanocatalysts for direct synthesis of H2O2 ACS Catal. 7 2017 2164 2170 H. Xu, D. Cheng, Y. Gao, Design of High-Performance Pd-Based Alloy Nanocatalysts for Direct Synthesis of H2O2, ACS Catal., 7 (2017) 2164-2170. [21] H. Xu D. Cheng Y. Gao X.C. Zeng Assessment of catalytic activities of gold nanoclusters with simple structure descriptors ACS Catal. 8 2018 9702 9710 H. Xu, D. Cheng, Y. Gao, X.C. Zeng, Assessment of Catalytic Activities of Gold Nanoclusters with Simple Structure Descriptors, ACS Catal., 8 (2018) 9702-9710. [22] S. Chen J. Zaffran B. Yang Descriptor design in the computational screening of Ni-Based catalysts with balanced activity and stability for dry reforming of methane reaction ACS Catal. 2020 3074 3083 S. Chen, J. Zaffran, B. Yang, Descriptor Design in the Computational Screening of Ni-Based Catalysts with Balanced Activity and Stability for Dry Reforming of Methane Reaction, ACS Catal., (2020) 3074-3083. [23] K. Yang J. Zaffran B. Yang Fast prediction of oxygen reduction reaction activity on carbon nanotubes with a localized geometric descriptor Phys. Chem. Chem. Phys. 22 2020 890 895 K. Yang, J. Zaffran, B. Yang, Fast prediction of oxygen reduction reaction activity on carbon nanotubes with a localized geometric descriptor, Phys. Chem. Chem. Phys., 22 (2020) 890-895. [24] H. Xin A. Holewinski S. Linic Predictive structure–Reactivity models for rapid screening of Pt-Based multimetallic electrocatalysts for the oxygen reduction reaction ACS Catal. 2 2012 12 16 H. Xin, A. Holewinski, S. Linic, Predictive Structure–Reactivity Models for Rapid Screening of Pt-Based Multimetallic Electrocatalysts for the Oxygen Reduction Reaction, ACS Catal., 2 (2012) 12-16. [25] X. Ma Z. Li L.E.K. Achenie H. Xin Machine-learning-Augmented chemisorption model for CO2 electroreduction catalyst screening J. Phys. Chem. Lett. 6 2015 3528 3533 X. Ma, Z. Li, L.E.K. Achenie, H. Xin, Machine-Learning-Augmented Chemisorption Model for CO2 Electroreduction Catalyst Screening, J. Phys. Chem. Lett., 6 (2015) 3528-3533. [26] H. Xin A. Holewinski N. Schweitzer E. Nikolla S. Linic Electronic structure engineering in heterogeneous catalysis: identifying novel alloy catalysts based on rapid screening for materials with desired electronic properties Top. Catal. 55 2012 376 390 H. Xin, A. Holewinski, N. Schweitzer, E. Nikolla, S. Linic, Electronic Structure Engineering in Heterogeneous Catalysis: Identifying Novel Alloy Catalysts Based on Rapid Screening for Materials with Desired Electronic Properties, Top. Catal., 55 (2012) 376-390. [27] A. Holewinski H. Xin E. Nikolla S. Linic Identifying optimal active sites for heterogeneous catalysis by metal alloys based on molecular descriptors and electronic structure engineering Curr. Opin. Chem. Eng. 2 2013 312 319 A. Holewinski, H. Xin, E. Nikolla, S. Linic, Identifying optimal active sites for heterogeneous catalysis by metal alloys based on molecular descriptors and electronic structure engineering, Curr. Opin. Chem. Eng., 2 (2013) 312-319. [28] S. Wang H. Xin Predicting catalytic activity of high-entropy alloys for electrocatalysis Chem 5 2019 502 504 S. Wang, H. Xin, Predicting Catalytic Activity of High-Entropy Alloys for Electrocatalysis, Chem, 5 (2019) 502-504. [29] Z. Li S. Wang W.S. Chin L.E. Achenie H. Xin High-throughput screening of bimetallic catalysts enabled by machine learning J. Mater. Chem. A Mater. Energy Sustain. 5 2017 24131 24138 Z. Li, S. Wang, W.S. Chin, L.E. Achenie, H. Xin, High-throughput screening of bimetallic catalysts enabled by machine learning, J. Mater. Chem. A, 5 (2017) 24131-24138. [30] Z. Li X. Ma H. Xin Feature engineering of machine-learning chemisorption models for catalyst design Catal. Today 280 2017 232 238 Z. Li, X. Ma, H. Xin, Feature engineering of machine-learning chemisorption models for catalyst design, Catal. Today, 280 (2017) 232-238. [31] J.S. Smith O. Isayev A.E. Roitberg ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost Chem. Sci. 8 2017 3192 3203 J.S. Smith, O. Isayev, A.E. Roitberg, ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost, Chem. Sci., 8 (2017) 3192-3203. [32] J. Ma R.P. Sheridan A. Liaw G.E. Dahl V. Svetnik Deep neural nets as a method for quantitative structure–Activity relationships J. Chem. Inf. Model. 55 2015 263 274 J. Ma, R.P. Sheridan, A. Liaw, G.E. Dahl, V. Svetnik, Deep Neural Nets as a Method for Quantitative Structure–Activity Relationships, J. Chem. Inf. Model., 55 (2015) 263-274. [33] M. Bredel E. Jacoby Chemogenomics: an emerging strategy for rapid target and drug discovery Nat. Rev. Genet. 5 2004 262 275 M. Bredel, E. Jacoby, Chemogenomics: an emerging strategy for rapid target and drug discovery, Nat. Rev. Genet., 5 (2004) 262-275. [34] M. Tsubaki K. Tomii J. Sese Compound–protein interaction prediction with end-to-end learning of neural networks for graphs and sequences Bioinformatics 35 2018 309 318 M. Tsubaki, K. Tomii, J. Sese, Compound–protein interaction prediction with end-to-end learning of neural networks for graphs and sequences, Bioinformatics, 35 (2018) 309-318. [35] D. Weininger SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules J. Chem. Inf. Model. 28 1988 31 36 D. Weininger, SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules, J. Chem. Inf. Model., 28 (1988) 31-36. [36] J. Behler M. Parrinello Generalized neural-network representation of high-dimensional potential-energy surfaces Phys. Rev. Lett. 98 2007 146401 J. Behler, M. Parrinello, Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces, Phys. Rev. Lett., 98 (2007) 146401. [37] A.P. Bartók R. Kondor G. Csányi On representing chemical environments Phys. Rev. B 87 2013 184115 A.P. Bartók, R. Kondor, G. Csányi, On representing chemical environments, Phys. Rev. B, 87 (2013) 184115. [38] S.-D. Huang C. Shang X.-J. Zhang Z.-P. Liu Material discovery by combining stochastic surface walking global optimization with a neural network Chem. Sci. 8 2017 6327 6337 S.-D. Huang, C. Shang, X.-J. Zhang, Z.-P. Liu, Material discovery by combining stochastic surface walking global optimization with a neural network, Chem. Sci., 8 (2017) 6327-6337. [39] R. Jinnouchi R. Asahi Predicting catalytic activity of nanoparticles by a DFT-Aided machine-learning algorithm J. Phys. Chem. Lett. 8 2017 4279 4283 R. Jinnouchi, R. Asahi, Predicting Catalytic Activity of Nanoparticles by a DFT-Aided Machine-Learning Algorithm, J. Phys. Chem. Lett., 8 (2017) 4279-4283. [40] M.O.J. Jäger E.V. Morooka F. Federici Canova L. Himanen A.S. Foster Machine learning hydrogen adsorption on nanoclusters through structural descriptors npj Comput. Mater. 4 2018 37 M.O.J. Jäger, E.V. Morooka, F. Federici Canova, L. Himanen, A.S. Foster, Machine learning hydrogen adsorption on nanoclusters through structural descriptors, npj Comput. Mater., 4 (2018) 37. [41] R.C. Glem A. Bender C.H. Arnby L. Carlsson S. Boyer J. Smith Circular fingerprints: flexible molecular descriptors with applications from physical chemistry to ADME IDrugs 9 2006 199 204 R.C. Glem, A. Bender, C.H. Arnby, L. Carlsson, S. Boyer, J. Smith, Circular fingerprints: flexible molecular descriptors with applications from physical chemistry to ADME, IDrugs, 9 (2006) 199-204. [42] D. Rogers M. Hahn Extended-connectivity fingerprints J. Chem. Inf. Model. 50 2010 742 754 D. Rogers, M. Hahn, Extended-Connectivity Fingerprints, J. Chem. Inf. Model., 50 (2010) 742-754. [43] N. Cohen S.W. Benson Estimation of heats of formation of organic compounds by additivity methods Chem. Rev. 93 1993 2419 2438 N. Cohen, S.W. Benson, Estimation of heats of formation of organic compounds by additivity methods, Chem. Rev., 93 (1993) 2419-2438. [44] M. Salciccioli S.M. Edie D.G. Vlachos Adsorption of acid, Ester, and ether functional groups on Pt: fast prediction of thermochemical properties of adsorbed oxygenates via DFT-Based group additivity methods J. Phys. Chem. C 116 2012 1873 1886 M. Salciccioli, S.M. Edie, D.G. Vlachos, Adsorption of Acid, Ester, and Ether Functional Groups on Pt: Fast Prediction of Thermochemical Properties of Adsorbed Oxygenates via DFT-Based Group Additivity Methods, J. Phys. Chem. C, 116 (2012) 1873-1886. [45] V. Vorotnikov D.G. Vlachos Group additivity and modified linear scaling relations for estimating surface thermochemistry on transition metal surfaces: application to furanics J. Phys. Chem. C 119 2015 10417 10426 V. Vorotnikov, D.G. Vlachos, Group Additivity and Modified Linear Scaling Relations for Estimating Surface Thermochemistry on Transition Metal Surfaces: Application to Furanics, J. Phys. Chem. C, 119 (2015) 10417-10426. [46] Z.W. Ulissi A.J. Medford T. Bligaard J.K. Nørskov To address surface reaction network complexity using scaling relations machine learning and DFT calculations Nat. Commun. 8 2017 14621 Z.W. Ulissi, A.J. Medford, T. Bligaard, J.K. Nørskov, To address surface reaction network complexity using scaling relations machine learning and DFT calculations, Nature Communications, 8 (2017) 14621. [47] A.J. Chowdhury W. Yang E. Walker O. Mamun A. Heyden G.A. Terejanu Prediction of adsorption energies for chemical species on metal catalyst surfaces using machine learning J. Phys. Chem. C 122 2018 28142 28150 A.J. Chowdhury, W. Yang, E. Walker, O. Mamun, A. Heyden, G.A. Terejanu, Prediction of Adsorption Energies for Chemical Species on Metal Catalyst Surfaces Using Machine Learning, J. Phys. Chem. C, 122 (2018) 28142-28150. [48] Z. Wu B. Ramsundar Evan N. Feinberg J. Gomes C. Geniesse A.S. Pappu K. Leswing V. Pande MoleculeNet: a benchmark for molecular machine learning Chem. Sci. 9 2018 513 530 Z. Wu, B. Ramsundar, Evan N. Feinberg, J. Gomes, C. Geniesse, A.S. Pappu, K. Leswing, V. Pande, MoleculeNet: a benchmark for molecular machine learning, Chem. Sci., 9 (2018) 513-530. [49] S. Kearnes K. McCloskey M. Berndl V. Pande P. Riley Molecular graph convolutions: moving beyond fingerprints J. Comput. Aided Mol. Des. 30 2016 595 608 S. Kearnes, K. McCloskey, M. Berndl, V. Pande, P. Riley, Molecular graph convolutions: moving beyond fingerprints, J. Comput. Aided Mol. Des., 30 (2016) 595-608. [50] G. Landrum, RDKit: Open-Source Cheminformatics Software. [51] A.J. Medford C. Shi M.J. Hoffmann A.C. Lausche S.R. Fitzgibbon T. Bligaard J.K. Nørskov CatMAP: A Software Package for Descriptor-Based Microkinetic Mapping of Catalytic Trends Catal. Lett. 145 2015 794 807 A.J. Medford, C. Shi, M.J. Hoffmann, A.C. Lausche, S.R. Fitzgibbon, T. Bligaard, J.K. Nørskov, CatMAP: A Software Package for Descriptor-Based Microkinetic Mapping of Catalytic Trends, Catal. Lett., 145 (2015) 794-807. [52] B. Ramsundar P. Eastman P. Walters V. Pande K. Leswing Z. Wu Deep learning for the life sciences O’Reilly Media 2019 B. Ramsundar, P. Eastman, P. Walters, V. Pande, K. Leswing, Z. Wu, Deep Learning for the Life Sciences, O'Reilly Media2019. [53] N. Srivastava G. Hinton A. Krizhevsky I. Sutskever R. Salakhutdinov Dropout: a simple way to prevent neural networks from overfitting JMLR.org 2014 N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov, Dropout: a simple way to prevent neural networks from overfitting, JMLR.org2014. [54] S. Ioffe C. Szegedy Batch normalization: accelerating deep network training by reducing internal covariate shift Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, JMLR.Org, Lille, France 2015 448 456 S. Ioffe, C. Szegedy, Batch normalization: accelerating deep network training by reducing internal covariate shift, Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, JMLR.org, Lille, France, 2015, pp. 448–456. [55] D. Opitz R. Maclin Popular ensemble methods: an empirical study J. Artif. Intell. Res. 11 1999 169 198 D. Opitz, R. Maclin, Popular Ensemble Methods: An Empirical Study, J. Artif. Intell. Res., 11 (1999) 169-198. [56] H. Tin Kam The random subspace method for constructing decision forests IEEE Trans. Pattern Anal. Mach. Intell. 20 1998 832 844 H. Tin Kam, The random subspace method for constructing decision forests, IEEE Trans. Pattern Anal. Mach. Intell., 20 (1998) 832-844. [57] L. Breiman Random forests Mach. Learn. 45 2001 5 32 L. Breiman, Random Forests, Mach. Learn., 45 (2001) 5-32. [58] X. Li R. Chiong Z. Hu D. Cornforth A.J. Page Improved representations of heterogeneous carbon reforming catalysis using machine learning J. Chem. Theory Comput. 15 2019 6882 6894 X. Li, R. Chiong, Z. Hu, D. Cornforth, A.J. Page, Improved Representations of Heterogeneous Carbon Reforming Catalysis Using Machine Learning, J. Chem. Theory Comput., 15 (2019) 6882-6894.",
      "scopus-id": "85093945121",
      "coredata": {
        "eid": "1-s2.0-S2468823120305290",
        "dc:description": "Computational studies of heterogeneous catalysis processes depend on massive electronic structure calculations to obtain the energies of intermediates and transition states. To speed up this process, several machine-learning-based methods were proposed for the prediction of surface species energies. Here we developed a new method to represent all surface species with molecular graph, a data structure which is easy to read and extendable, but seldom utilized in catalysis studies. The molecular graph dataset consists of 315 C1/C2 surface intermediates and transition states on Rh(111), which are all possible intermediates in the complex reaction network of ethanol synthesis from syngas. Three recently proposed graph-based machine learning methods, namely graph convolutions, weave and graph neural network, were employed to train models and predict the energies from molecular graphs. Furthermore, two ensemble models combining the abovementioned models were built, using which the best RMSE and MAE reaches 0.19 and 0.15 eV, respectively. In addition, error of activation energies predicted with graph neural network was compared with that predicted using traditional BEP relations, and error of the prediction for surface intermediate energies and transition state energies were compared. Finally, possible directions of using the developed methods in extendable energy predictions were suggested and discussed.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2020-12-31",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S2468823120305290",
        "dc:creator": [
          {
            "@_fa": "true",
            "$": "Wang, Baochuan"
          },
          {
            "@_fa": "true",
            "$": "Gu, Tangjie"
          },
          {
            "@_fa": "true",
            "$": "Lu, Yijun"
          },
          {
            "@_fa": "true",
            "$": "Yang, Bo"
          }
        ],
        "link": [
          {
            "@_fa": "true",
            "@rel": "self",
            "@href": "https://api.elsevier.com/content/article/pii/S2468823120305290"
          },
          {
            "@_fa": "true",
            "@rel": "scidir",
            "@href": "https://www.sciencedirect.com/science/article/pii/S2468823120305290"
          }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S2468-8231(20)30529-0",
        "prism:volume": "498",
        "articleNumber": "111266",
        "prism:publisher": "Elsevier B.V.",
        "dc:title": "Prediction of energies for reaction intermediates and transition states on catalyst surfaces using graph-based machine learning models",
        "prism:copyright": "© 2020 Elsevier B.V. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "24688231",
        "dcterms:subject": [
          {
            "@_fa": "true",
            "$": "Machine learning"
          },
          {
            "@_fa": "true",
            "$": "Molecular graph"
          },
          {
            "@_fa": "true",
            "$": "Energy prediction"
          },
          {
            "@_fa": "true",
            "$": "Surface species"
          },
          {
            "@_fa": "true",
            "$": "BEP relation"
          }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Molecular Catalysis",
        "openaccessSponsorType": null,
        "prism:pageRange": "111266",
        "pubType": "fla",
        "prism:coverDisplayDate": "December 2020",
        "prism:doi": "10.1016/j.mcat.2020.111266",
        "prism:startingPage": "111266",
        "dc:identifier": "doi:10.1016/j.mcat.2020.111266",
        "openaccessSponsorName": null
      },
      "objects": {
        "object": [
          {
            "@category": "standard",
            "@height": "303",
            "@width": "679",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "40096",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "798",
            "@width": "679",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "106391",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "268",
            "@width": "340",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "28492",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "209",
            "@width": "679",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "48443",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "194",
            "@width": "717",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "27550",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "200",
            "@width": "260",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-ga1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "17362",
            "@ref": "ga1",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "271",
            "@width": "340",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "19597",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "standard",
            "@height": "167",
            "@width": "679",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-sc1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "26640",
            "@ref": "sc1",
            "@mimetype": "image/jpeg"
          },
          {
            "@category": "thumbnail",
            "@height": "98",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6672",
            "@ref": "gr4",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "139",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8014",
            "@ref": "gr3",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "208",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11377",
            "@ref": "gr6",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "68",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8990",
            "@ref": "gr5",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "59",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4091",
            "@ref": "gr2",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "213",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-ga1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "15179",
            "@ref": "ga1",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "205",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "10112",
            "@ref": "gr1",
            "@mimetype": "image/gif"
          },
          {
            "@category": "thumbnail",
            "@height": "54",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-sc1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4727",
            "@ref": "sc1",
            "@mimetype": "image/gif"
          },
          {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-mmc1.docx?httpAccept=%2A%2F%2A",
            "@multimediatype": "Microsoft Word file",
            "@type": "APPLICATION",
            "@size": "771983",
            "@ref": "mmc1",
            "@mimetype": "application/word"
          },
          {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2468823120305290-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "774894",
            "@ref": "am",
            "@mimetype": "application/pdf"
          }
        ]
      },
      "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85093945121"
      }
    }
  }
}